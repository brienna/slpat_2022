{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and prep lexicon\n",
    "\n",
    "In this notebook, I download and prepare the extended lexicon created by [Nicolas et al. (2021)](https://onlinelibrary.wiley.com/doi/epdf/10.1002/ejsp.2724), in which words are annotated with either +1 or -1 to indicate a positive or negative association with a given sub-dimension of the Stereotype Content Model.\n",
    "\n",
    "### Table of Contents:\n",
    "- [1. Download lexicon](#1.-download-lexicon)\n",
    "- [2. Prepare lexicon](#2.-prepare-lexicon)\n",
    "    - [2.1. Apply filters](#21-apply-filters)\n",
    "    - [2.2. Reformat data frame](#22-reformat-data-frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/brienna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/brienna/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "LEXICON_RAW_PATH = '../data/raw/lexicon.csv' # raw lexicon that was downloaded from the paper\n",
    "LEXICON_INPUT_PATH = '../data/input/lexicon.csv' # processed lexicon that is ready for use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download lexicon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>preprocessed word 1 (lacksknowledge to NA)</th>\n",
       "      <th>preprocessed word 2 (no spaces)</th>\n",
       "      <th>preprocessed word 3 (lemmatized)</th>\n",
       "      <th>preprocessed word 4 (minus one trailing s)</th>\n",
       "      <th>Positive valence</th>\n",
       "      <th>Negative valence</th>\n",
       "      <th>Neutral valence</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Sociability dictionary</th>\n",
       "      <th>...</th>\n",
       "      <th>body_covering dictionary</th>\n",
       "      <th>beauty dictionary</th>\n",
       "      <th>beauty direction</th>\n",
       "      <th>insults dictionary</th>\n",
       "      <th>stem dictionary</th>\n",
       "      <th>humanities dictionary</th>\n",
       "      <th>art dictionary</th>\n",
       "      <th>social_groups dictionary</th>\n",
       "      <th>Lacks_knowledge dictionary</th>\n",
       "      <th>fortune dictionary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>ab</td>\n",
       "      <td>ab</td>\n",
       "      <td>ab</td>\n",
       "      <td>ab</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aba</td>\n",
       "      <td>aba</td>\n",
       "      <td>aba</td>\n",
       "      <td>aba</td>\n",
       "      <td>aba</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>abandon</td>\n",
       "      <td>abandon</td>\n",
       "      <td>abandon</td>\n",
       "      <td>abandon</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandoned infant</td>\n",
       "      <td>abandoned infant</td>\n",
       "      <td>abandonedinfant</td>\n",
       "      <td>abandonedinfant</td>\n",
       "      <td>abandonedinfant</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      original word preprocessed word 1 (lacksknowledge to NA)  \\\n",
       "0                aa                                         aa   \n",
       "1                ab                                         ab   \n",
       "2               aba                                        aba   \n",
       "3           abandon                                    abandon   \n",
       "4  abandoned infant                           abandoned infant   \n",
       "\n",
       "  preprocessed word 2 (no spaces) preprocessed word 3 (lemmatized)  \\\n",
       "0                              aa                               aa   \n",
       "1                              ab                               ab   \n",
       "2                             aba                              aba   \n",
       "3                         abandon                          abandon   \n",
       "4                 abandonedinfant                  abandonedinfant   \n",
       "\n",
       "  preprocessed word 4 (minus one trailing s)  Positive valence  \\\n",
       "0                                         aa              0.00   \n",
       "1                                         ab              0.00   \n",
       "2                                        aba              0.00   \n",
       "3                                    abandon              0.06   \n",
       "4                            abandonedinfant              0.00   \n",
       "\n",
       "   Negative valence  Neutral valence  Sum  Sociability dictionary  ...  \\\n",
       "0              0.00             1.00    1                       0  ...   \n",
       "1              0.00             1.00    1                       0  ...   \n",
       "2              0.00             1.00    1                       0  ...   \n",
       "3              0.38             0.56    2                       0  ...   \n",
       "4              0.00             1.00    1                       0  ...   \n",
       "\n",
       "   body_covering dictionary  beauty dictionary  beauty direction  \\\n",
       "0                         0                  0               NaN   \n",
       "1                         0                  0               NaN   \n",
       "2                         0                  0               NaN   \n",
       "3                         0                  0               NaN   \n",
       "4                         0                  0               NaN   \n",
       "\n",
       "   insults dictionary  stem dictionary  humanities dictionary  art dictionary  \\\n",
       "0                   0                0                      0               0   \n",
       "1                   0                0                      0               0   \n",
       "2                   0                0                      0               0   \n",
       "3                   0                0                      0               0   \n",
       "4                   0                0                      0               0   \n",
       "\n",
       "   social_groups dictionary  Lacks_knowledge dictionary  fortune dictionary  \n",
       "0                         0                           0                   0  \n",
       "1                         0                           0                   0  \n",
       "2                         0                           0                   0  \n",
       "3                         0                           0                   0  \n",
       "4                         0                           0                   0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download lexicon\n",
    "scm_df = pd.read_csv('https://osf.io/m9nb5/download')\n",
    "scm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist locally\n",
    "scm_df.to_csv(LEXICON_RAW_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare lexicon\n",
    "\n",
    "### 2.1. Apply filters \n",
    "\n",
    "Here, I do the following: \n",
    "- Remove attributes that don't show up in the 4 sub-dimensions\n",
    "- Remove attributes that are not adjectives\n",
    "    - Our selected template sentences only work with adjectives.\n",
    "- Remove multi-word attributes\n",
    "    - I originally added this filter to limit the variations between any two attributes. This way, if BERT responds differently to them, we can be more confident that the difference isn't a side effect of something such as sentence length. However, it turns out that when we filter out adjectives, all multi-word attributes got removed. So this is a note that this filter changes nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: 14449\n"
     ]
    }
   ],
   "source": [
    "# Read in lexicon again\n",
    "scm_df = pd.read_csv(LEXICON_RAW_PATH)\n",
    "print('Attributes:', len(scm_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: 4630\n"
     ]
    }
   ],
   "source": [
    "# Remove attributes that don't show up in the 4 sub-dimensions\n",
    "mask_morality = ((scm_df['Morality direction'] == -1.0) | (scm_df['Morality direction'] == 1.0))\n",
    "mask_sociability = ((scm_df['Sociability direction'] == -1.0) | (scm_df['Sociability direction'] == 1.0))\n",
    "mask_ability =  ((scm_df['Ability direction'] == -1.0) | (scm_df['Ability direction'] == 1.0))\n",
    "mask_agency = ((scm_df['Agency direction'] == -1.0) | (scm_df['Agency direction'] == 1.0))\n",
    "scm_df = scm_df.loc[(mask_morality | mask_sociability | mask_ability | mask_agency),:].reset_index(drop=True)\n",
    "print('Attributes:', len(scm_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: 1256\n"
     ]
    }
   ],
   "source": [
    "# Remove attributes that are not adjectives\n",
    "def is_target_pos(word, target_pos='a'):\n",
    "    pos_list = []\n",
    "    for synset in wn.synsets(word):\n",
    "        synset_components = synset.name().split('.')\n",
    "        if synset_components[0] == word: \n",
    "            pos_list.append(synset.pos())\n",
    "\n",
    "    if target_pos in pos_list:\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "scm_df = scm_df[scm_df['original word'].apply(lambda w: is_target_pos(w, 'a') or is_target_pos(w, 's'))].reset_index(drop=True)\n",
    "print('Attributes:', len(scm_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: 1256\n"
     ]
    }
   ],
   "source": [
    "# Remove multi-word attributes\n",
    "mask_one_word = (scm_df['original word'].str.split(' ').apply(len) == 1)\n",
    "scm_df = scm_df.loc[mask_one_word,:].reset_index(drop=True)\n",
    "print('Attributes:', len(scm_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves 1,256 attributes in this lexicon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Reformat data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"original word\" column, drop some other columns\n",
    "scm_df = scm_df.rename(columns={'original word': 'Attribute'})\n",
    "scm_df = scm_df[['Attribute', 'Ability direction', 'Morality direction', 'Sociability direction', 'Agency direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Unsociable</th>\n",
       "      <th>Sociable</th>\n",
       "      <th>Immoral</th>\n",
       "      <th>Moral</th>\n",
       "      <th>Dependent</th>\n",
       "      <th>Independent</th>\n",
       "      <th>Unable</th>\n",
       "      <th>Able</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aberrant</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abhorrent</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abject</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>able</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute  Unsociable  Sociable  Immoral  Moral  Dependent  Independent  \\\n",
       "0   aberrant       False     False     True  False      False        False   \n",
       "1  abhorrent       False     False     True  False      False        False   \n",
       "2     abject       False     False    False  False       True        False   \n",
       "3       able       False     False    False  False      False        False   \n",
       "4   abnormal       False     False     True  False      False        False   \n",
       "\n",
       "   Unable   Able  \n",
       "0   False  False  \n",
       "1   False  False  \n",
       "2   False  False  \n",
       "3   False   True  \n",
       "4   False  False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat columns\n",
    "dummies_df = pd.get_dummies(scm_df, \n",
    "                            columns=['Sociability direction', 'Morality direction', 'Agency direction', 'Ability direction'])\n",
    "dummies_df = dummies_df.rename(columns={'Sociability direction_-1.0': 'Unsociable',\n",
    "                           'Sociability direction_1.0': 'Sociable',\n",
    "                           'Morality direction_-1.0': 'Immoral',\n",
    "                           'Morality direction_1.0': 'Moral',\n",
    "                           'Agency direction_-1.0': 'Dependent',\n",
    "                           'Agency direction_1.0': 'Independent',\n",
    "                           'Ability direction_-1.0': 'Unable',\n",
    "                           'Ability direction_1.0': 'Able'})\n",
    "scm_df = dummies_df.drop(['Sociability direction_0.0', 'Morality direction_0.0', 'Agency direction_0.0', 'Ability direction_0.0'], axis=1)\n",
    "scm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed lexicon\n",
    "scm_df.to_csv(LEXICON_INPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slpat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
